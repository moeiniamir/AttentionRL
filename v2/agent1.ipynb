{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:50.922521172Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:50.113529464Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:30.931609958Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:30.124617050Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ]
    }
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script pack_existing_segs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.300770945Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:50.921840758Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.335443232Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:30.932201025Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ]
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from pack_existing_segs import *\n",
    "from tianshou.utils import WandbLogger, LazyLogger\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import pickle\n",
    "from enum import Enum\n",
    "from IPython import display\n",
    "from pack_existing_segs import unpack_new_seg_out\n",
    "import utils as ut\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import gc\n",
    "from torchvision.models import resnet50\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import json\n",
    "from pathlib import Path\n",
    "import tianshou as ts\n",
    "from gymnasium.wrappers import TimeLimit\n",
    "import einops\n",
    "from transformers import ViTImageProcessor, ViTModel\n",
    "from customs import custom_offpolicy_trainer, CustomDQNPolicy, CustomOffpolicyTrainer\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.301058023Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.300294091Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.335729135Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.331166072Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ]
    }
   },
   "outputs": [],
   "source": [
    "# if username is server use cuda\n",
    "if os.environ['USER'] == 'server':\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "else:\n",
    "    device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "# if __name__ == '__main__':\n",
    "#     torch.multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.322426210Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.300970301Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.342518775Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.335237470Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ]
    }
   },
   "outputs": [],
   "source": [
    "class COCODataset(D.Dataset):\n",
    "    def __init__(self, root=\"../Data/COCO17\", train=True, length=None, indices=None, no_seg=False):\n",
    "        self.root = Path(root)\n",
    "        self.no_seg = no_seg\n",
    "\n",
    "        with open(self.root / 'annotations/captions_train2017.json', 'r') as f:\n",
    "            images_info = json.load(f)\n",
    "        self.file_name_to_id = dict()\n",
    "        for image_info in images_info['images']:\n",
    "            self.file_name_to_id[image_info['file_name']] = image_info['id']\n",
    "            self.file_name_to_id[image_info['id']] = image_info['file_name']  # for reverse search\n",
    "\n",
    "        with open(self.root / 'cap_dict.json', 'r') as f:\n",
    "            self.captions_dict = json.load(f)\n",
    "\n",
    "        if train:\n",
    "            self.image_files = glob.glob(os.path.join(self.root / 'train2017', \"*.jpg\"))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            # self.image_files = glob.glob(os.path.join(self.root / 'val2017', \"*.jpg\"))\n",
    "\n",
    "        assert length is None or indices is None, \"Cannot specify both len and indices\"\n",
    "        assert length is not None or indices is not None, \"Must specify either len or indices\"\n",
    "        if length is not None:\n",
    "            self.image_files = random.sample(self.image_files, length)\n",
    "        else:\n",
    "            self.image_files = [self.image_files[i] for i in indices]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_file = self.image_files[index]\n",
    "        image = PIL.Image.open(image_file)\n",
    "        image = image.convert('RGB')\n",
    "        file_name = image_file.split('/')[-1]\n",
    "        # image_tensor = transforms.ToTensor()(image)\n",
    "        image_tensor = transforms.Compose([\n",
    "            transforms.Resize((image.height // 2, image.width // 2)),\n",
    "            transforms.ToTensor()\n",
    "        ])(image)\n",
    "\n",
    "        if self.no_seg:\n",
    "            seg_output = torch.empty((0, 0, 0))\n",
    "        else:\n",
    "            with open(self.root / 'train2017seg' / (str(self.file_name_to_id[file_name]) + '.pkl'), 'rb') as f:\n",
    "                packed_seg_out = pickle.load(f)\n",
    "            seg_output = unpack_new_seg_out(packed_seg_out)\n",
    "            seg_output = transforms.Resize(image_tensor.shape[1:])(torch.from_numpy(seg_output).to(device))\n",
    "\n",
    "        return image_tensor, seg_output, self.file_name_to_id[file_name]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.347086651Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.322708910Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.347346175Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.344416471Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ]
    }
   },
   "outputs": [],
   "source": [
    "class Actions(Enum):\n",
    "    UP = 0\n",
    "    RIGHT = 1\n",
    "    DOWN = 2\n",
    "    LEFT = 3\n",
    "    # STAY = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.369727810Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.323112809Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.358756443Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.346531546Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ]
    }
   },
   "outputs": [],
   "source": [
    "class History:\n",
    "    def __init__(self, patch_size, max_row=None, max_col=None):\n",
    "        self.patch_size = patch_size\n",
    "        if max_row is None:\n",
    "            self._min_row, self._min_col, self._max_row, self._max_col = None, None, None, None\n",
    "            self.pos_mask = None\n",
    "            self.history = None\n",
    "        else:\n",
    "            self._min_row, self._min_col, self._max_row, self._max_col = 0, 0, max_row, max_col\n",
    "            self.pos_mask = torch.ones(((max_row + 1) * patch_size[0], (max_col + 1) * patch_size[1]))\n",
    "            self.history = torch.zeros((3, (max_row + 1) * patch_size[0], (max_col + 1) * patch_size[1]))\n",
    "            # print(self.pos_mask.shape, self.history.shape)\n",
    "\n",
    "        self.curr_rel_row, self.curr_rel_col = None, None\n",
    "\n",
    "    def append(self, patch, row, col):\n",
    "        if self._min_row is None:\n",
    "            self._min_row, self._min_col, self._max_row, self._max_col = row, col, row, col\n",
    "            self.history = patch\n",
    "            self.pos_mask = torch.ones(patch.shape[1:])\n",
    "        else:\n",
    "            if row < self._min_row:\n",
    "                # pad history with zeros on top to account for row difference\n",
    "                self.history = torch.cat(\n",
    "                    (torch.zeros(3, self.patch_size[0] * (self._min_row - row), self.history.shape[2]), self.history),\n",
    "                    dim=1)\n",
    "                self.pos_mask = torch.cat(\n",
    "                    (torch.ones(self.patch_size[0] * (self._min_row - row), self.history.shape[2]), self.pos_mask),\n",
    "                    dim=0)\n",
    "                self._min_row = row\n",
    "            if row > self._max_row:\n",
    "                # pad history with zeros on bottom to account for row difference\n",
    "                self.history = torch.cat(\n",
    "                    (self.history, torch.zeros(3, self.patch_size[0] * (row - self._max_row), self.history.shape[2])),\n",
    "                    dim=1)\n",
    "                self.pos_mask = torch.cat(\n",
    "                    (self.pos_mask, torch.ones(self.patch_size[0] * (row - self._max_row), self.history.shape[2])),\n",
    "                    dim=0)\n",
    "                self._max_row = row\n",
    "            if col < self._min_col:\n",
    "                # pad history with zeros on left to account for col difference\n",
    "                self.history = torch.cat(\n",
    "                    (torch.zeros(3, self.history.shape[1], self.patch_size[1] * (self._min_col - col)), self.history),\n",
    "                    dim=2)\n",
    "                self.pos_mask = torch.cat(\n",
    "                    (torch.ones(self.history.shape[1], self.patch_size[1] * (self._min_col - col)), self.pos_mask),\n",
    "                    dim=1)\n",
    "                self._min_col = col\n",
    "            if col > self._max_col:\n",
    "                # pad history with zeros on right to account for col difference\n",
    "                self.history = torch.cat(\n",
    "                    (self.history, torch.zeros(3, self.history.shape[1], self.patch_size[1] * (col - self._max_col))),\n",
    "                    dim=2)\n",
    "                self.pos_mask = torch.cat(\n",
    "                    (self.pos_mask, torch.ones(self.history.shape[1], self.patch_size[1] * (col - self._max_col))),\n",
    "                    dim=1)\n",
    "                self._max_col = col\n",
    "            # add patch to history\n",
    "            top = self.patch_size[0] * (row - self._min_row)\n",
    "            bottom = top + self.patch_size[0]\n",
    "            left = self.patch_size[1] * (col - self._min_col)\n",
    "            right = left + self.patch_size[1]\n",
    "\n",
    "            # print(f\"{self._min_row=}, {self._min_col=}, {self._max_row=}, {self._max_col=} {top=}, {bottom=}, {left=}, {right=}\")\n",
    "            self.history[:, top:bottom, left:right] = patch\n",
    "            self.pos_mask[top:bottom, left:right] = 0\n",
    "        self.curr_rel_col = col - self._min_col\n",
    "        self.curr_rel_row = row - self._min_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.378347321Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.334132608Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.367461923Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.354222992Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ]
    }
   },
   "outputs": [],
   "source": [
    "class Environment(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"rgb_array\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, dataset, patch_size=(64, 64)):\n",
    "        self.dataloader = D.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "        self.iterator = iter(self.dataloader)\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        self.img_emtpy_patch = torch.zeros((patch_size[0]//2, patch_size[1]//2))\n",
    "        self.img_emtpy_patch[::2, ::2] = 1\n",
    "        self.seg_empty_patch = torch.zeros((patch_size[0]//2, patch_size[1]//2))\n",
    "\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'center': spaces.Box(low=0, high=255, shape=(3, self.patch_size[0], self.patch_size[1]), dtype=np.uint8),\n",
    "            'surrounding': spaces.Box(low=0, high=255, shape=(3, self.patch_size[0], self.patch_size[1]), dtype=np.uint8),\n",
    "        })\n",
    "        self.action_space = spaces.Discrete(len(Actions))\n",
    "\n",
    "        self.im = None\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        try:\n",
    "            # Samples the batch\n",
    "            self.current_image, self.current_seg, self.image_id = next(self.iterator)\n",
    "        except StopIteration:\n",
    "            # restart the iterator if the previous iterator is exhausted.\n",
    "            self.iterator = iter(self.dataloader)\n",
    "            self.current_image, self.current_seg, self.image_id = next(self.iterator)\n",
    "\n",
    "        # remove the batch dimension\n",
    "        self.current_image = self.current_image[0]\n",
    "        self.current_seg = self.current_seg[0]\n",
    "\n",
    "        # cut the image and seg to multiples of patch size\n",
    "        initial_height, initial_width = self.current_image.shape[1:]\n",
    "        self.current_image = self.current_image[:, :initial_height // self.patch_size[0] * self.patch_size[0],\n",
    "                              :initial_width // self.patch_size[1] * self.patch_size[1]]\n",
    "        self.current_seg = self.current_seg[:, :initial_height // self.patch_size[0] * self.patch_size[0],\n",
    "                           :initial_width // self.patch_size[1] * self.patch_size[1]]\n",
    "\n",
    "        # add empty patch to all 4 edges of image and seg\n",
    "        # here's an example:\n",
    "            # empty_patch = torch.zeros(8, 8)\n",
    "            # empty_patch[::2, ::2] = 1\n",
    "            # image = torch.rand(3, 64, 64)\n",
    "            # repeated_empty_patch = empty_patch.repeat(image.shape[0], 1, image.shape[2] // empty_patch.shape[1])\n",
    "            # image = torch.cat([repeated_empty_patch, image, repeated_empty_patch], dim=1)\n",
    "            # repeated_empty_patch = empty_patch.repeat(image.shape[0], image.shape[1] // empty_patch.shape[0], 1)\n",
    "            # image = torch.cat([repeated_empty_patch, image, repeated_empty_patch], dim=2)\n",
    "        repeated_empty_patch = self.img_emtpy_patch.repeat(self.current_image.shape[0], 1,\n",
    "                                                           self.current_image.shape[2] // self.img_emtpy_patch.shape[1])\n",
    "        self.current_image = torch.cat([repeated_empty_patch, self.current_image, repeated_empty_patch], dim=1)\n",
    "        repeated_empty_patch = self.img_emtpy_patch.repeat(self.current_image.shape[0],\n",
    "                                                           self.current_image.shape[1] // self.img_emtpy_patch.shape[0], 1)\n",
    "        self.current_image = torch.cat([repeated_empty_patch, self.current_image, repeated_empty_patch], dim=2)\n",
    "\n",
    "        repeated_empty_patch = self.seg_empty_patch.repeat(self.current_seg.shape[0], 1,\n",
    "                                                           self.current_seg.shape[2] // self.seg_empty_patch.shape[1])\n",
    "        self.current_seg = torch.cat([repeated_empty_patch, self.current_seg, repeated_empty_patch], dim=1)\n",
    "        repeated_empty_patch = self.seg_empty_patch.repeat(self.current_seg.shape[0],\n",
    "                                                           self.current_seg.shape[1] // self.seg_empty_patch.shape[0], 1)\n",
    "        self.current_seg = torch.cat([repeated_empty_patch, self.current_seg, repeated_empty_patch], dim=2)\n",
    "\n",
    "\n",
    "        self.image_id = str(self.image_id.item())\n",
    "        _, self.height, self.width = self.current_image.shape\n",
    "        self.captions = self.dataloader.dataset.captions_dict[self.image_id]\n",
    "        self.max_row, self.max_col = (self.height - self.patch_size[0]) // self.patch_size[0], (\n",
    "                self.width - self.patch_size[1]) // self.patch_size[1]\n",
    "        self.row, self.col = self.max_row // 2, self.max_col // 2\n",
    "\n",
    "        # self.seen_patches = torch.zeros((self.max_row + 1, self.max_col + 1))\n",
    "        self.seen_patches = torch.full((self.max_row + 1, self.max_col + 1), -0.5)\n",
    "        self.seen_masks = torch.zeros(self.current_seg.shape[0]).to(device)\n",
    "        # self.history = History(self.patch_size)\n",
    "        self.history = History(self.patch_size, self.max_row, self.max_col)\n",
    "\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def _get_patch(self):\n",
    "        start_row, end_row = self.row * self.patch_size[0], (self.row + 1) * self.patch_size[0]\n",
    "        start_col, end_col = self.col * self.patch_size[1], (self.col + 1) * self.patch_size[1]\n",
    "        return self.current_image[:, start_row: end_row, start_col: end_col]\n",
    "\n",
    "    def _get_history(self, new_patch):\n",
    "        self.history.append(new_patch, self.row, self.col)\n",
    "        return self.history\n",
    "\n",
    "    def _get_obs(self):\n",
    "        patch = self._get_patch()\n",
    "        history = self._get_history(patch)\n",
    "        return {\n",
    "            # 'center': patch,\n",
    "            # 'surrounding': self._get_surrounding(),\n",
    "            'history': {\n",
    "                'history': history.history,\n",
    "                'pos_mask': history.pos_mask,\n",
    "                'curr_rel_row': torch.tensor(history.curr_rel_row),\n",
    "                'curr_rel_col': torch.tensor(history.curr_rel_col),\n",
    "                'patch_size': torch.tensor(history.patch_size),\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _get_surrounding(self):\n",
    "        # get surrounding area and pad with zero on the corresponding side that is out of bound\n",
    "        surrounding = torch.zeros((3, 3 * self.patch_size[0], 3 * self.patch_size[1]))\n",
    "        target_start_row = self.patch_size[0] if self.row == 0 else 0\n",
    "        target_end_row = 2 * self.patch_size[0] if self.row == self.max_row else 3 * self.patch_size[0]\n",
    "        target_start_col = self.patch_size[1] if self.col == 0 else 0\n",
    "        target_end_col = 2 * self.patch_size[1] if self.col == self.max_col else 3 * self.patch_size[1]\n",
    "        start_row = max(0, self.row - 1) * self.patch_size[0]\n",
    "        end_row = min(self.max_row + 1, self.row + 2) * self.patch_size[0]\n",
    "        start_col = max(0, self.col - 1) * self.patch_size[1]\n",
    "        end_col = min(self.max_col + 1, self.col + 2) * self.patch_size[1]\n",
    "        surrounding[:, target_start_row: target_end_row, target_start_col: target_end_col] = self.current_image[:,\n",
    "                                                                                             start_row: end_row,\n",
    "                                                                                             start_col: end_col]\n",
    "        # resize surrounding to match the patch size\n",
    "        surrounding = transforms.Resize(self.patch_size)(surrounding)\n",
    "        return surrounding\n",
    "\n",
    "    def _reward_seg(self):\n",
    "        start_row, end_row = self.row * self.patch_size[0], (self.row + 1) * self.patch_size[0]\n",
    "        start_col, end_col = self.col * self.patch_size[1], (self.col + 1) * self.patch_size[1]\n",
    "        patch_seg = self.current_seg[:, start_row: end_row, start_col: end_col]\n",
    "        patch_seg = patch_seg.sum(dim=(1, 2)) / self.current_seg.sum(dim=(1, 2))\n",
    "        seen_threshold = 0.7\n",
    "        seg_reward = (patch_seg > seen_threshold)\n",
    "        seg_reward = seg_reward * (1 - self.seen_masks)\n",
    "        self.seen_masks += seg_reward\n",
    "        seg_reward = seg_reward.sum().item()\n",
    "\n",
    "        return seg_reward\n",
    "\n",
    "    def _reward_return(self):\n",
    "        reward = -self.seen_patches[self.row, self.col]\n",
    "        self.seen_patches[self.row, self.col] = 1\n",
    "        return reward\n",
    "\n",
    "    def _covered_done(self):\n",
    "        if self.seen_patches.sum() == (self.max_row + 1) * (self.max_col + 1):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def step(self, action):\n",
    "        if Actions(action) == Actions.UP:\n",
    "            self.row = self.row - 1 if self.row > 0 else self.row\n",
    "        elif Actions(action) == Actions.RIGHT:\n",
    "            self.col = self.col + 1 if self.col < self.max_col else self.col\n",
    "        elif Actions(action) == Actions.DOWN:\n",
    "            self.row = self.row + 1 if self.row < self.max_row else self.row\n",
    "        elif Actions(action) == Actions.LEFT:\n",
    "            self.col = self.col - 1 if self.col > 0 else self.col\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action\")\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        done = self._covered_done()\n",
    "        # reward_seg = self._reward_seg()\n",
    "        reward_return = self._reward_return()\n",
    "        reward_done = 100 if done else 0\n",
    "        reward = reward_return + reward_done\n",
    "        truncated = False\n",
    "        info = {}\n",
    "        return obs, reward, done, truncated, info\n",
    "\n",
    "    def _get_render_image(self):\n",
    "        start_row, end_row = self.row * self.patch_size[0], (self.row + 1) * self.patch_size[0]\n",
    "        start_col, end_col = self.col * self.patch_size[1], (self.col + 1) * self.patch_size[1]\n",
    "        image = einops.rearrange(self.trail_image, 'c h w -> h w c')\n",
    "        image[start_row: end_row, start_col: end_col] = 0.8 * image[start_row: end_row, start_col: end_col]\n",
    "        return image\n",
    "\n",
    "    def render(self):\n",
    "        if self.im is None:\n",
    "            self.trail_image = self.current_image.clone()\n",
    "            self.im = plt.imshow(self._get_render_image())\n",
    "            display.display(plt.gcf())\n",
    "        else:\n",
    "            # display.clear_output(wait=True)\n",
    "            self.im.set_data(self._get_render_image())\n",
    "            self.im.axes.add_image(self.im)\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.378626528Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.347345989Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.375775887Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.366145068Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ]
    }
   },
   "outputs": [],
   "source": [
    "class Q_network_surr_transformer(nn.Module):\n",
    "    def __init__(self, action_count, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.feature_extractor = resnet50(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(self.feature_extractor.children())[:-2])\n",
    "\n",
    "        transformer_decoder_layer = nn.TransformerDecoderLayer(d_model=2048, nhead=8, batch_first=True)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(transformer_decoder_layer, num_layers=1)\n",
    "\n",
    "        state_shape = 2048\n",
    "        action_shape = action_count\n",
    "        self.dueling_head = ts.utils.net.common.Net(state_shape, action_shape, hidden_sizes=[1024], dueling_param=(\n",
    "            {\n",
    "                \"hidden_sizes\": [512, 512],\n",
    "            },\n",
    "            {\n",
    "                \"hidden_sizes\": [512, 512],\n",
    "            }\n",
    "        ), device=device)\n",
    "\n",
    "        self.resize33 = transforms.Resize((3, 3))\n",
    "        self.resize11 = transforms.Resize((1, 1))\n",
    "\n",
    "        # freeze the feature extractor\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, obs, **kwargs):\n",
    "        sur_patch = torch.tensor(obs['surrounding']).to(device)\n",
    "        cent_patch = torch.tensor(obs['center']).to(device)\n",
    "\n",
    "        surr_enc = einops.rearrange(self.resize33(self.feature_extractor(sur_patch)), 'b c h w -> b (h w) c')\n",
    "        cent_enc = einops.rearrange(self.resize11(self.feature_extractor(cent_patch)), 'b c h w -> b (h w) c')\n",
    "\n",
    "        transformer_out = self.transformer_decoder(cent_enc, surr_enc).squeeze(1)\n",
    "        duel_out = self.dueling_head(transformer_out)\n",
    "        return duel_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.378726532Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.347751342Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.375950068Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.370236037Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ]
    }
   },
   "outputs": [],
   "source": [
    "class Q_network(nn.Module):\n",
    "    def __init__(self, action_count, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.vit = ViTModel.from_pretrained('facebook/dino-vits8', use_mask_token=True,\n",
    "                                            proxies={'http': '127.0.0.1:10809', 'https': '127.0.0.1:10809'}).to(device)\n",
    "        self.vit_patch_size = self.vit.config.patch_size\n",
    "\n",
    "        state_shape = 384\n",
    "        action_shape = action_count\n",
    "        self.dueling_head = ts.utils.net.common.Net(state_shape, action_shape, hidden_sizes=[512, 512], dueling_param=(\n",
    "            {\n",
    "                \"hidden_sizes\": [512],\n",
    "            },\n",
    "            {\n",
    "                \"hidden_sizes\": [512],\n",
    "            }\n",
    "        ), device=device)\n",
    "\n",
    "        for param in self.vit.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, obs, **kwargs):\n",
    "        history = obs['history']\n",
    "\n",
    "        bool_masked_pos = history.pos_mask[:, ::self.vit_patch_size, ::self.vit_patch_size].flatten(start_dim=1)\n",
    "\n",
    "        out = self.vit(history.history.to(device),\n",
    "                       bool_masked_pos=bool_masked_pos,\n",
    "                       interpolate_pos_encoding=True)\n",
    "\n",
    "        patch_h, patch_w = history.patch_size[:, 0] // self.vit_patch_size, history.patch_size[:,\n",
    "                                                                            1] // self.vit_patch_size  # todo optimize\n",
    "        w = history.history.shape[3] // self.vit_patch_size\n",
    "        i, j = history.curr_rel_row * patch_h, history.curr_rel_col * patch_w\n",
    "        curr_index = i * w + j + (patch_h // 2) * w + (patch_w // 2)\n",
    "        # print(f\"{out.last_hidden_state.shape=} {i=} {j=} {w=} {patch_w=} {patch_h=} {curr_index=} {history.curr_rel_col=} {history.curr_rel_row=} {history.history.shape=}\")\n",
    "        lhs = out.last_hidden_state\n",
    "        indices = einops.repeat(curr_index, 'b -> b 1 h', h=lhs.shape[2])\n",
    "        curr_enc = torch.gather(lhs, 1, indices.to(device))\n",
    "        # curr_enc = lhs[torch.arange(lhs.shape[0]), curr_index, :]\n",
    "\n",
    "        duel_out = self.dueling_head(curr_enc)\n",
    "        # print(f\"{curr_enc[:, :4]=} \\n {duel_out=}\")\n",
    "        return duel_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_train_fn(policy, eps_train, inital_phase):\n",
    "    def train_fn(epoch, env_step):\n",
    "        policy.set_eps(eps_train[epoch - 1])\n",
    "        if epoch >= inital_phase:\n",
    "            for param in policy.model.vit.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        if epoch >= 0 and epoch % 50 == 0:\n",
    "            torch.save(policy.state_dict(), f'saved/policy_{wandb_logger.wandb_run.name if use_wandb else uuid.uuid4().hex}.pt')\n",
    "\n",
    "        wandb_logger.write('train', trainer.env_step, {\"epoch\": epoch})\n",
    "    return train_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.378901552Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:27:52.349735874Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.378122737Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-12T15:29:32.375907458Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ]
    }
   },
   "outputs": [],
   "source": [
    "def register_hooks(model):\n",
    "    hook0 = model.dueling_head.Q.model[-1].register_forward_hook(lambda self, input, output: print(f\"Q: {output}\"))\n",
    "    hook1 = model.dueling_head.V.model[-1].register_forward_hook(lambda self, input, output: print(f\"V: {output}\"))\n",
    "    # hook2 = model.dueling_head.model.model[0].register_forward_hook(lambda self, input, output: print(f\"net: {output}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbdime-conflicts": {
     "local_diff": [
      {
       "diff": [
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:28:08.578141786Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "end_time",
         "op": "patch"
        },
        {
         "diff": [
          {
           "key": 0,
           "op": "addrange",
           "valuelist": [
            "2023-07-15T16:28:02.566059669Z"
           ]
          },
          {
           "key": 0,
           "length": 1,
           "op": "removerange"
          }
         ],
         "key": "start_time",
         "op": "patch"
        }
       ],
       "key": "ExecuteTime",
       "op": "patch"
      }
     ],
     "remote_diff": [
      {
       "key": "ExecuteTime",
       "op": "remove"
      }
     ]
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "    lr, epoch, batch_size = 8e-5, 1500, 20\n",
    "    initial_phase = 0\n",
    "    test_num = 10\n",
    "    gamma, n_step, target_freq = 0.98, 1, 400\n",
    "    buffer_size = 20000\n",
    "    eps_start, eps_end = 0.9, 0.05\n",
    "    eps_train, eps_test = np.linspace(eps_start, eps_end, epoch), 0\n",
    "    step_per_epoch, step_per_collect = 2000, 100\n",
    "    env_step_limit = step_per_collect\n",
    "\n",
    "    dataset = COCODataset(train=True, indices=[12], no_seg=True)\n",
    "    # train_envs = ts.env.SubprocVectorEnv([lambda: TimeLimit(Environment(dataset), 100) for _ in range(1)])\n",
    "    train_envs = ts.env.DummyVectorEnv([lambda: TimeLimit(Environment(dataset, (32, 32)), env_step_limit) for _ in range(1)])\n",
    "    # test_envs = ts.env.SubprocVectorEnv([lambda: TimeLimit(Environment(dataset), 100) for _ in range(1)])\n",
    "    action_count = train_envs.get_env_attr('action_space', 0)[0].n\n",
    "    net = Q_network(action_count).to(device)\n",
    "    optim = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    # policy = ts.policy.DQNPolicy(net, optim, discount_factor=gamma, estimation_step=n_step, target_update_freq=target_freq)\n",
    "    policy = CustomDQNPolicy(net, optim, discount_factor=gamma, estimation_step=n_step, target_update_freq=target_freq)\n",
    "    # register_hooks(policy.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "policy.load_state_dict(torch.load('saved/policy_true-flower-40.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    replay_buffer = ts.data.VectorReplayBuffer(buffer_size, len(train_envs))\n",
    "    train_collector = ts.data.Collector(policy, train_envs, replay_buffer, exploration_noise=True)\n",
    "    # test_collector = ts.data.Collector(policy, test_envs, exploration_noise=True)\n",
    "\n",
    "    use_wandb = True\n",
    "    if use_wandb:\n",
    "        wandb_logger = WandbLogger(\n",
    "            train_interval=1,\n",
    "            test_interval=1,\n",
    "            update_interval=1,\n",
    "            project=\"AttentionRL\",\n",
    "        )\n",
    "        wandb_logger.load(SummaryWriter(\"./logs\"))\n",
    "\n",
    "        wandb_logger.wandb_run.config['lr'] = lr\n",
    "        wandb_logger.wandb_run.config['epoch'] = epoch\n",
    "        wandb_logger.wandb_run.config['batch_size'] = batch_size\n",
    "        wandb_logger.wandb_run.config['initial_phase'] = initial_phase\n",
    "        wandb_logger.wandb_run.config['test_num'] = test_num\n",
    "        wandb_logger.wandb_run.config['gamma'] = gamma\n",
    "        wandb_logger.wandb_run.config['n_step'] = n_step\n",
    "        wandb_logger.wandb_run.config['target_freq'] = target_freq\n",
    "        wandb_logger.wandb_run.config['buffer_size'] = buffer_size\n",
    "        wandb_logger.wandb_run.config['eps_start'] = eps_start\n",
    "        wandb_logger.wandb_run.config['eps_end'] = eps_end\n",
    "        wandb_logger.wandb_run.config['step_per_epoch'] = step_per_epoch\n",
    "        wandb_logger.wandb_run.config['step_per_collect'] = step_per_collect\n",
    "        wandb_logger.wandb_run.config['env_step_limit'] = env_step_limit\n",
    "    else:\n",
    "        wandb_logger = LazyLogger()\n",
    "\n",
    "\n",
    "    trainer = CustomOffpolicyTrainer(\n",
    "        policy=policy, train_collector=train_collector, test_collector=None, episode_per_test=test_num, max_epoch=epoch,\n",
    "        step_per_epoch=step_per_epoch, step_per_collect=step_per_collect,\n",
    "        batch_size=batch_size, update_per_step=1 / step_per_collect * 4,\n",
    "        train_fn=get_train_fn(policy, eps_train, initial_phase),\n",
    "        test_fn=lambda epoch, env_step: policy.set_eps(eps_test),\n",
    "        stop_fn=lambda mean_rewards: mean_rewards >= 0,\n",
    "        logger= wandb_logger,\n",
    "    )\n",
    "    trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     env = TimeLimit(Environment(dataset, (32, 32)), 200)\n",
    "#     ut.show_masks_on_image(einops.rearrange(env.current_image, 'c h w -> h w c'), env.current_seg.cpu().numpy())\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # dataset = COCODataset(root=\"../Data/COCO17\", train=True, len=1)\n",
    "    policy.eval()\n",
    "    policy.set_eps(eps_test)\n",
    "    dataset = COCODataset(train=True, indices=[29], no_seg=True)\n",
    "    env = TimeLimit(Environment(dataset, (32, 32)), 100)\n",
    "    collector = ts.data.Collector(policy, env, exploration_noise=True)\n",
    "    collector.collect(n_episode=1, render=1/10)\n",
    "    # collector.collect(n_episode=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
