{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T14:04:36.445875915Z",
     "start_time": "2023-05-17T14:04:32.060985811Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook agent1.ipynb to script\r\n",
      "[NbConvertApp] Writing 10508 bytes to agent1.py\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/behnamnia/.conda/envs/rl39/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/home/behnamnia/.conda/envs/rl39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script agent1.ipynb --output agent1\n",
    "!jupyter nbconvert --to script pack_existing_segs.ipynb --output pack_existing_segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T14:04:36.493782183Z",
     "start_time": "2023-05-17T14:04:36.448125788Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agent1 import *\n",
    "from pack_existing_segs import *\n",
    "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation\n",
    "from transformers import SamModel, SamProcessor, pipeline\n",
    "import gc\n",
    "from utils import show_mask, show_masks_on_image\n",
    "from PIL import Image\n",
    "import requests\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T14:04:37.984396145Z",
     "start_time": "2023-05-17T14:04:36.496654574Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset = COCODataset(root=\"../Data/COCO17\", train=True)\n",
    "    generator = pipeline(\"mask-generation\", model=\"facebook/sam-vit-huge\", device=device)\n",
    "    for img in dataset:\n",
    "        if Path(f\"../Data/COCO17/train2017seg/{img[1]}.pkl\").exists():\n",
    "            continue\n",
    "        print('Processing', img[1])\n",
    "        image = transforms.ToPILImage()(img[0])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = generator(image, points_per_batch=64)\n",
    "        packed_outputs = pack_seg_out(outputs)\n",
    "\n",
    "        # plt.imshow(image)\n",
    "        # plt.show()\n",
    "        # show_masks_on_image(image, outputs['masks'])\n",
    "        # plt.show()\n",
    "        with open(f\"../Data/COCO17/train2017seg/{img[1]}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(packed_outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T14:04:37.989784647Z",
     "start_time": "2023-05-17T14:04:37.984800023Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-large-coco-panoptic\")\n",
    "# model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-large-coco-panoptic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T14:04:38.002090064Z",
     "start_time": "2023-05-17T14:04:37.991853965Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for img in dataset:\n",
    "#     image = transforms.ToPILImage()(img[0])\n",
    "#\n",
    "#     inputs = processor(images=image, return_tensors=\"pt\")\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#\n",
    "#     class_queries_logits = outputs.class_queries_logits\n",
    "#     masks_queries_logits = outputs.masks_queries_logits\n",
    "#     result = processor.post_process_panoptic_segmentation(outputs, target_sizes=[img[0].shape[2:0:-1]])\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()\n",
    "#     plt.imshow(result[0]['segmentation'])\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
