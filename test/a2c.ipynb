{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import torch, numpy as np, torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tianshou as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "task = 'CartPole-v1'\n",
    "lr, epoch, batch_size = 1e-3, 10, 64\n",
    "train_num, test_num = 10, 100\n",
    "gamma, n_step, target_freq = 0.9, 3, 320\n",
    "buffer_size = 20000\n",
    "eps_train, eps_test = 0.1, 0.05\n",
    "step_per_epoch, step_per_collect = 10000, 10\n",
    "# logger = ts.utils.TensorboardLogger(SummaryWriter('log/dqn'))  # TensorBoard is supported!\n",
    "# For other loggers: https://tianshou.readthedocs.io/en/master/tutorials/logger.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you can also try with SubprocVectorEnv\n",
    "train_envs = ts.env.DummyVectorEnv([lambda: gym.make(task) for _ in range(train_num)])\n",
    "test_envs = ts.env.DummyVectorEnv([lambda: gym.make(task) for _ in range(test_num)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tianshou.utils.net.common import Net\n",
    "# you can define other net by following the API:\n",
    "# https://tianshou.readthedocs.io/en/master/tutorials/dqn.html#build-the-network\n",
    "env = gym.make(task, render_mode='human')\n",
    "state_shape = env.observation_space.shape or env.observation_space.n\n",
    "action_shape = env.action_space.shape or env.action_space.n\n",
    "net = Net(state_shape=state_shape, action_shape=action_shape, hidden_sizes=[256, 256, 256])\n",
    "optim = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "policy = ts.policy.DQNPolicy(net, optim, gamma, n_step, target_update_freq=target_freq)\n",
    "train_collector = ts.data.Collector(policy, train_envs, ts.data.VectorReplayBuffer(buffer_size, train_num), exploration_noise=True)\n",
    "test_collector = ts.data.Collector(policy, test_envs, exploration_noise=True)  # because DQN uses epsilon-greedy method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 10001it [00:05, 1926.78it/s, env_step=10000, len=430, loss=0.258, n/ep=0, n/st=10, rew=430.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: 359.200000 ± 75.609391, best_reward: 359.200000 ± 75.609391 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 10001it [00:06, 1530.80it/s, env_step=20000, len=240, loss=0.316, n/ep=0, n/st=10, rew=240.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: 278.090000 ± 60.695650, best_reward: 359.200000 ± 75.609391 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 10001it [00:06, 1651.35it/s, env_step=30000, len=253, loss=0.081, n/ep=0, n/st=10, rew=253.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: 301.220000 ± 70.034360, best_reward: 359.200000 ± 75.609391 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 10001it [00:06, 1472.64it/s, env_step=40000, len=328, loss=0.027, n/ep=0, n/st=10, rew=328.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: 304.230000 ± 55.159560, best_reward: 359.200000 ± 75.609391 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 10001it [00:06, 1626.44it/s, env_step=50000, len=238, loss=0.016, n/ep=0, n/st=10, rew=238.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 204.920000 ± 25.458075, best_reward: 359.200000 ± 75.609391 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 10001it [00:06, 1640.95it/s, env_step=60000, len=98, loss=0.032, n/ep=0, n/st=10, rew=98.00]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 233.930000 ± 44.857609, best_reward: 359.200000 ± 75.609391 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 10001it [00:06, 1577.04it/s, env_step=70000, len=315, loss=0.035, n/ep=0, n/st=10, rew=315.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: 330.960000 ± 77.793306, best_reward: 359.200000 ± 75.609391 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 10001it [00:05, 1881.86it/s, env_step=80000, len=290, loss=0.033, n/ep=0, n/st=10, rew=290.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: 183.420000 ± 10.929026, best_reward: 359.200000 ± 75.609391 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 10001it [00:05, 1891.53it/s, env_step=90000, len=278, loss=0.069, n/ep=0, n/st=10, rew=278.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: 337.010000 ± 49.587397, best_reward: 359.200000 ± 75.609391 in #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 10001it [00:05, 1707.24it/s, env_step=100000, len=214, loss=0.029, n/ep=0, n/st=10, rew=214.00]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: 184.390000 ± 10.327531, best_reward: 359.200000 ± 75.609391 in #1\n",
      "Finished training! Use 66.77s\n",
      "CPU times: user 6min 37s, sys: 4.37 s, total: 6min 41s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = ts.trainer.offpolicy_trainer(\n",
    "    policy, train_collector, test_collector, epoch, step_per_epoch, step_per_collect,\n",
    "    test_num, batch_size, update_per_step=1 / step_per_collect,\n",
    "    train_fn=lambda epoch, env_step: policy.set_eps(eps_train),\n",
    "    test_fn=lambda epoch, env_step: policy.set_eps(eps_test),\n",
    "    stop_fn=lambda mean_rewards: mean_rewards >= env.spec.reward_threshold,\n",
    "    )\n",
    "print(f'Finished training! Use {result[\"duration\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m policy\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m      2\u001B[0m policy\u001B[38;5;241m.\u001B[39mset_eps(eps_test)\n\u001B[0;32m----> 3\u001B[0m collector \u001B[38;5;241m=\u001B[39m \u001B[43mts\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCollector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpolicy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexploration_noise\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m collector\u001B[38;5;241m.\u001B[39mcollect(n_episode\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, render\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m35\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/tianshou/data/collector.py:79\u001B[0m, in \u001B[0;36mCollector.__init__\u001B[0;34m(self, policy, env, buffer, preprocess_fn, exploration_noise)\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_action_space \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv\u001B[38;5;241m.\u001B[39maction_space\n\u001B[1;32m     78\u001B[0m \u001B[38;5;66;03m# avoid creating attribute outside __init__\u001B[39;00m\n\u001B[0;32m---> 79\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/tianshou/data/collector.py:130\u001B[0m, in \u001B[0;36mCollector.reset\u001B[0;34m(self, reset_buffer, gym_reset_kwargs)\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;66;03m# use empty Batch for \"state\" so that self.data supports slicing\u001B[39;00m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;66;03m# convert empty Batch to None when passing data to policy\u001B[39;00m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m Batch(\n\u001B[1;32m    120\u001B[0m     obs\u001B[38;5;241m=\u001B[39m{},\n\u001B[1;32m    121\u001B[0m     act\u001B[38;5;241m=\u001B[39m{},\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    128\u001B[0m     policy\u001B[38;5;241m=\u001B[39m{}\n\u001B[1;32m    129\u001B[0m )\n\u001B[0;32m--> 130\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset_env\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgym_reset_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reset_buffer:\n\u001B[1;32m    132\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset_buffer()\n",
      "File \u001B[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/tianshou/data/collector.py:146\u001B[0m, in \u001B[0;36mCollector.reset_env\u001B[0;34m(self, gym_reset_kwargs)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Reset all of the environments.\"\"\"\u001B[39;00m\n\u001B[1;32m    145\u001B[0m gym_reset_kwargs \u001B[38;5;241m=\u001B[39m gym_reset_kwargs \u001B[38;5;28;01mif\u001B[39;00m gym_reset_kwargs \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[0;32m--> 146\u001B[0m obs, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgym_reset_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess_fn:\n\u001B[1;32m    148\u001B[0m     processed_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess_fn(\n\u001B[1;32m    149\u001B[0m         obs\u001B[38;5;241m=\u001B[39mobs, info\u001B[38;5;241m=\u001B[39minfo, env_id\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv_num)\n\u001B[1;32m    150\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/tianshou/env/venvs.py:281\u001B[0m, in \u001B[0;36mBaseVectorEnv.reset\u001B[0;34m(self, id, **kwargs)\u001B[0m\n\u001B[1;32m    279\u001B[0m \u001B[38;5;66;03m# send(None) == reset() in worker\u001B[39;00m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mid\u001B[39m:\n\u001B[0;32m--> 281\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    282\u001B[0m ret_list \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworkers[i]\u001B[38;5;241m.\u001B[39mrecv() \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mid\u001B[39m]\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;28misinstance\u001B[39m(ret_list[\u001B[38;5;241m0\u001B[39m], (\u001B[38;5;28mtuple\u001B[39m, \u001B[38;5;28mlist\u001B[39m)) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(ret_list[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret_list[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m1\u001B[39m], \u001B[38;5;28mdict\u001B[39m)\n\u001B[1;32m    287\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/tianshou/env/worker/dummy.py:36\u001B[0m, in \u001B[0;36mDummyEnvWorker.send\u001B[0;34m(self, action, **kwargs)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msend\u001B[39m(\u001B[38;5;28mself\u001B[39m, action: Optional[np\u001B[38;5;241m.\u001B[39mndarray], \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 36\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresult \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     38\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresult \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv\u001B[38;5;241m.\u001B[39mstep(action)\n",
      "File \u001B[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gymnasium/wrappers/time_limit.py:69\u001B[0m, in \u001B[0;36mTimeLimit.reset\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Resets the environment with :param:`**kwargs` and sets the number of steps elapsed to zero.\u001B[39;00m\n\u001B[1;32m     61\u001B[0m \n\u001B[1;32m     62\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;124;03m    The reset environment\u001B[39;00m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_elapsed_steps \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gymnasium/wrappers/order_enforcing.py:43\u001B[0m, in \u001B[0;36mOrderEnforcing.reset\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Resets the environment with `kwargs`.\"\"\"\u001B[39;00m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_reset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 43\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gymnasium/wrappers/env_checker.py:47\u001B[0m, in \u001B[0;36mPassiveEnvChecker.reset\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m env_reset_passive_checker(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gymnasium/envs/classic_control/cartpole.py:206\u001B[0m, in \u001B[0;36mCartPoleEnv.reset\u001B[0;34m(self, seed, options)\u001B[0m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps_beyond_terminated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrender_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 206\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32), {}\n",
      "File \u001B[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gymnasium/envs/classic_control/cartpole.py:296\u001B[0m, in \u001B[0;36mCartPoleEnv.render\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    293\u001B[0m gfxdraw\u001B[38;5;241m.\u001B[39mhline(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msurf, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscreen_width, carty, (\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m    295\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msurf \u001B[38;5;241m=\u001B[39m pygame\u001B[38;5;241m.\u001B[39mtransform\u001B[38;5;241m.\u001B[39mflip(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msurf, \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 296\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscreen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msurf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrender_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    298\u001B[0m     pygame\u001B[38;5;241m.\u001B[39mevent\u001B[38;5;241m.\u001B[39mpump()\n",
      "\u001B[0;31merror\u001B[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "policy.eval()\n",
    "policy.set_eps(eps_test)\n",
    "collector = ts.data.Collector(policy, env, exploration_noise=True)\n",
    "collector.collect(n_episode=2, render=1 / 35)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
